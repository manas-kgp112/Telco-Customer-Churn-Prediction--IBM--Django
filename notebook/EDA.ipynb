{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../artifacts/data\"\n",
    "files = os.listdir(data_path)\n",
    "files\n",
    "for file in files:\n",
    "    file_name = os.path.splitext(file)[0]\n",
    "    globals()[f'{file_name}_df'] = pd.read_excel(os.path.join(data_path, file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_s = [\n",
    "    \n",
    "    Telco_customer_churn_df,\n",
    "\n",
    "    Telco_customer_churn_demographics_df,\n",
    "\n",
    "    Telco_customer_churn_location_df,\n",
    "    \n",
    "    Telco_customer_churn_population_df,\n",
    "    \n",
    "    Telco_customer_churn_services_df,\n",
    "    \n",
    "    Telco_customer_churn_services_df,\n",
    "    \n",
    "    CustomerChurn_df\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and EDA/Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Telco_customer_churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Telco_customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Telco_customer_churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating all categorical values in the dataset\n",
    "categorical_data = []\n",
    "for column in Telco_customer_churn_df:\n",
    "    value_counts = pd.value_counts(Telco_customer_churn_df[column])\n",
    "    value_counts_len = len(value_counts.index.to_list())\n",
    "\n",
    "    if value_counts_len < 10 and value_counts_len!=1:\n",
    "        categorical_data.append(column)\n",
    "        print(f\"Unique values for column '{column}' : {value_counts.index.to_list()} having len {value_counts_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telco_customer_churn_df_copy = Telco_customer_churn_df.copy().fillna(''),\n",
    "# Telco_customer_churn_demographics_df_copy = Telco_customer_churn_demographics_df.copy().fillna(''),\n",
    "# Telco_customer_churn_location_df_copy = Telco_customer_churn_location_df.copy().fillna(''),\n",
    "# Telco_customer_churn_population_df_copy = Telco_customer_churn_population_df.copy().fillna(''),\n",
    "# Telco_customer_churn_services_df_copy = Telco_customer_churn_services_df.copy().fillna(''),\n",
    "# Telco_customer_churn_services_df_copy = Telco_customer_churn_services_df.copy().fillna(''),\n",
    "\n",
    "# df_s = [\n",
    "#     Telco_customer_churn_df_copy,\n",
    "#     Telco_customer_churn_demographics_df_copy,\n",
    "#     Telco_customer_churn_location_df_copy,\n",
    "#     Telco_customer_churn_population_df_copy,\n",
    "#     Telco_customer_churn_services_df_copy,\n",
    "#     Telco_customer_churn_services_df_copy\n",
    "# ]\n",
    "# os.makedirs(\"./df_info\", exist_ok=True)\n",
    "# count = 0\n",
    "# for df in enumerate(df_s):\n",
    "#     file_path = f'./df_info/{count}.txt'\n",
    "#     count+=1\n",
    "#     info_str = df.info(buf=None)\n",
    "#     with open(file_path, \"w\") as f:\n",
    "#         f.write(info_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 5 df's (subset of telco_churn) demographics/location etc. are to be dealt with.\n",
    "categorical_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom plot\n",
    "fig, axes = plt.subplots(9,2, figsize=(15,40))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(categorical_data)):\n",
    "    features = categorical_data[i]\n",
    "    sns.countplot(x=features, data=Telco_customer_churn_df, palette = 'Set2', ax=axes[i], hue='Churn Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_data = ['Monthly Charges', 'Churn Score', 'CLTV']\n",
    "fig, axes = plt.subplots(3,1, figsize=(10,15))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(continous_data)):\n",
    "    features = continous_data[i]\n",
    "    sns.histplot(x=features, data=Telco_customer_churn_df, ax=axes[i], palette='Paired', hue='Churn Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_data = ['Tenure in Months', 'Total Revenue', 'Total Charges']\n",
    "fig, axes = plt.subplots(3,1, figsize=(10,15))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(continous_data)):\n",
    "    features = continous_data[i]\n",
    "    sns.histplot(x=features, data=Telco_customer_churn_services_df, ax=axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,10))\n",
    "sns.violinplot(Telco_customer_churn_demographics_df, y='Number of Dependents', color='m')\n",
    "plt.xlabel(\"Number of Dependents\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Number of Dependents Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of People around the city.\n",
    "fig = px.scatter_mapbox(\n",
    "    Telco_customer_churn_df,\n",
    "    lat = 'Latitude',\n",
    "    lon = 'Longitude',\n",
    "    color = 'Churn Score',\n",
    "    hover_name = 'Churn Value',\n",
    "    # size = 'Churn Value',\n",
    "    zoom = 5, \n",
    "    height = 800,\n",
    "    width = 800\n",
    ")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reason for churn -> most imp to analyze\n",
    "plt.figure(figsize=(25,40))\n",
    "sns.countplot(y='Churn Reason', data=Telco_customer_churn_df)\n",
    "# plt.legend()\n",
    "plt.title(\"Churn Reasons\")\n",
    "sns.set(font_scale=5)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Telco_customer_churn_df.copy()\n",
    "df.drop(['CustomerID', 'Lat Long', 'Churn Reason', 'Country', 'State', 'City', 'Zip Code', 'Churn Label', 'Count', 'Churn Score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_encoder = OneHotEncoder()\n",
    "# categorical_features = [\n",
    "#     'Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Multiple Lines',\n",
    "#     'Internet Service','Online Security', 'Online Backup', 'Device Protection', 'Tech Support', \n",
    "#     'Streaming TV', 'Streaming Movies', 'Contract','Paperless Billing', 'Payment Method', 'Churn Value'\n",
    "# ]\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cat_features = [\n",
    "    'Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Multiple Lines',\n",
    "    'Internet Service','Online Security', 'Online Backup', 'Device Protection', 'Tech Support', \n",
    "    'Streaming TV', 'Streaming Movies', 'Contract','Paperless Billing', 'Payment Method'\n",
    "]\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_mat = ohe.fit_transform(df[dummy_cat_features])\n",
    "df_new = pd.DataFrame(encoded_mat, columns=ohe.get_feature_names_out(dummy_cat_features))\n",
    "df_new.info()\n",
    "# import pickle\n",
    "# with open(\"../artifacts/transformer/preprocessor.pkl\", \"rb\") as file:\n",
    "#         preprocessor = pickle.load(file)\n",
    "\n",
    "# transformed_data = preprocessor.transform(df)\n",
    "# df_n = pd.DataFrame(transformed_data, columns=df.columns)\n",
    "# df_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap{Matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"Churn Value\"].sort_values(ascending=False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(corr_matrix[\"Churn Value\"].sort_values(ascending=False).to_frame(), annot = True,linewidths = 0.4,linecolor = 'black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi SQuare Test for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_cat_features = df.loc[:,categorical_features]\n",
    "chi_target = df.loc[:,'Churn Value']\n",
    "best_features_chi = SelectKBest(score_func=chi2, k='all')\n",
    "features_fit_chi = best_features_chi.fit(chi_cat_features, chi_target)\n",
    "features_score_chi = pd.DataFrame(data=features_fit_chi.scores_, index=list(chi_cat_features.columns), columns=['Chi Squared Score'])\n",
    "features_score_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(features_score_chi.sort_values(ascending = False,by = 'Chi Squared Score'), annot=True, fmt = '.2f')\n",
    "plt.title(\"Chi Square Test for Ctaegorical Feature Selection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cat_features = [\n",
    "    'Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Multiple Lines',\n",
    "    'Internet Service','Online Security', 'Online Backup', 'Device Protection', 'Tech Support', \n",
    "    'Streaming TV', 'Streaming Movies', 'Contract','Paperless Billing', 'Payment Method'\n",
    "]\n",
    "df = pd.get_dummies(df, columns=dummy_cat_features, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Churn Value'], axis=1).copy()\n",
    "Y = df['Churn Value']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Gaussian Naive Bayes' : GaussianNB(),\n",
    "    'K Nearest Neighbors' : KNeighborsClassifier(),\n",
    "    'Support Vector Machine' : SVC(probability=True),\n",
    "    'Decision Tree Classifier' : DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier' : RandomForestClassifier(),\n",
    "    'Bagging Classifier' : BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(),\n",
    "        n_estimators=10\n",
    "    ),\n",
    "    'Gradient Boosting Classifier' : GradientBoostingClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=50\n",
    "    ),\n",
    "    'Stacking Classifier' : StackingClassifier(\n",
    "        estimators=[\n",
    "            ('log_reg', LogisticRegression()),\n",
    "            ('random_forest', RandomForestClassifier()),\n",
    "            ('grad_boost', GradientBoostingClassifier())\n",
    "        ]\n",
    "    ),\n",
    "    'Voting Classifier' : VotingClassifier(\n",
    "        estimators=[\n",
    "            ('log_reg', LogisticRegression()),\n",
    "            ('random_forest', RandomForestClassifier()),\n",
    "            ('grad_boost', GradientBoostingClassifier())\n",
    "        ]\n",
    "    ),\n",
    "    'XgBoost' : XGBClassifier(),\n",
    "    'LightGBM' : LGBMClassifier(),\n",
    "    'Catboost' : CatBoostClassifier()\n",
    "    }\n",
    "model_accs = []\n",
    "model_precs = []\n",
    "model_recalls = []\n",
    "model_f1s = []\n",
    "\n",
    "\n",
    "# Models used for Training\n",
    "'''\n",
    "    1) RandomForestClassifier(n_estimators=100, class_weight={0:1,1:3})\n",
    "    2) XGBClassifier()\n",
    "    3) LGBMClassifier(learning_rate=0.09,max_depth=-5,scale_pos_weight =3,\n",
    "                    random_state=42, objective = 'binary')\n",
    "    4) Bagging Classifier\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"Model : {model_name}\")\n",
    "    print(f\"Accuracy : {accuracy}\")\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams training\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10],'max_iter':[1000, 10000]},\n",
    "    'Random Forest': {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10]},\n",
    "    'Gradient Boosting': {'learning_rate': [0.1, 0.01], 'n_estimators': [100, 200, 300]},\n",
    "    'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': [0.1, 0.01]},\n",
    "    'Stacking': {},  # Stacking doesn't have hyperparameters to tune\n",
    "    'Bagging': {'n_estimators': [10, 20, 30]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 150]},\n",
    "    'Voting': {}  # Voting doesn't have hyperparameters to tune\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=100, class_weight={0:1,1:3})\n",
    "random_forest_clf.fit(X_train, Y_train)\n",
    "Y_pred = random_forest_clf.predict(X_test)\n",
    "models.append(\"Random Forest Classifier\")\n",
    "model_accs.append(accuracy_score(Y_test, Y_pred))\n",
    "model_precs.append(precision_score(Y_test, Y_pred))\n",
    "model_recalls.append(recall_score(Y_test, Y_pred))\n",
    "model_f1s.append(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the classification report\n",
    "\n",
    "print(f\"Accuracy score : {accuracy_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision score : {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall score : {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"F1 score : {f1_score(Y_test, Y_pred)}\")\n",
    "print(' ')\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "cm_disp = ConfusionMatrixDisplay(cm, display_labels=['No Churn', 'Churn'])\n",
    "cm_disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()\n",
    "xgboost.fit(X_train, Y_train)\n",
    "Y_pred = xgboost.predict(X_test)\n",
    "models.append(\"XGBoost\")\n",
    "model_accs.append(accuracy_score(Y_test, Y_pred))\n",
    "model_precs.append(precision_score(Y_test, Y_pred))\n",
    "model_recalls.append(recall_score(Y_test, Y_pred))\n",
    "model_f1s.append(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the classification report\n",
    "\n",
    "print(f\"Accuracy score : {accuracy_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision score : {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall score : {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"F1 score : {f1_score(Y_test, Y_pred)}\")\n",
    "print(' ')\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "cm_disp = ConfusionMatrixDisplay(cm, display_labels=['No Churn', 'Churn'])\n",
    "cm_disp.plot()\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(learning_rate=0.09,max_depth=-5,scale_pos_weight =3, random_state=42, objective = 'binary')\n",
    "lgbm.fit(X_train, Y_train)\n",
    "Y_pred = lgbm.predict(X_test)\n",
    "models.append(\"Light GBM\")\n",
    "model_accs.append(accuracy_score(Y_test, Y_pred))\n",
    "model_precs.append(precision_score(Y_test, Y_pred))\n",
    "model_recalls.append(recall_score(Y_test, Y_pred))\n",
    "model_f1s.append(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the classification report\n",
    "\n",
    "print(f\"Accuracy score : {accuracy_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision score : {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall score : {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"F1 score : {f1_score(Y_test, Y_pred)}\")\n",
    "print(' ')\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "cm_disp = ConfusionMatrixDisplay(cm, display_labels=['No Churn', 'Churn'])\n",
    "cm_disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=123)\n",
    "bagging_clf.fit(X_train, Y_train)\n",
    "Y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "models.append(\"Bagging Classifier\")\n",
    "model_accs.append(accuracy_score(Y_test, Y_pred))\n",
    "model_precs.append(precision_score(Y_test, Y_pred))\n",
    "model_recalls.append(recall_score(Y_test, Y_pred))\n",
    "model_f1s.append(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the classification report\n",
    "\n",
    "print(f\"Accuracy score : {accuracy_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision score : {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall score : {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"F1 score : {f1_score(Y_test, Y_pred)}\")\n",
    "print(' ')\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "cm_disp = ConfusionMatrixDisplay(cm, display_labels=['No Churn', 'Churn'])\n",
    "cm_disp.plot()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'Model': models,\n",
    "    'Precision': model_precs,\n",
    "    'Acuuracy': model_accs,\n",
    "    'Recall': model_recalls,\n",
    "    'F1': model_f1s\n",
    "}\n",
    "\n",
    "models_df = pd.DataFrame(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
