{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Customer Churn Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn_evaluation import plot\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import Gradio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../artifacts/data\"\n",
    "files = os.listdir(data_path)\n",
    "files\n",
    "for file in files:\n",
    "    file_name = os.path.splitext(file)[0]\n",
    "    globals()[f'{file_name}_df'] = pd.read_excel(os.path.join(data_path, file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_s = [\n",
    "    \n",
    "    Telco_customer_churn_df,\n",
    "\n",
    "    Telco_customer_churn_demographics_df,\n",
    "\n",
    "    Telco_customer_churn_location_df,\n",
    "    \n",
    "    Telco_customer_churn_population_df,\n",
    "    \n",
    "    Telco_customer_churn_services_df,\n",
    "    \n",
    "    Telco_customer_churn_services_df,\n",
    "    \n",
    "    CustomerChurn_df\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and EDA/Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Telco_customer_churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Telco_customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Telco_customer_churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating all categorical values in the dataset\n",
    "categorical_data = []\n",
    "for column in Telco_customer_churn_df:\n",
    "    value_counts = pd.value_counts(Telco_customer_churn_df[column])\n",
    "    value_counts_len = len(value_counts.index.to_list())\n",
    "\n",
    "    if value_counts_len < 10 and value_counts_len!=1:\n",
    "        categorical_data.append(column)\n",
    "        print(f\"Unique values for column '{column}' : {value_counts.index.to_list()} having len {value_counts_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 5 df's (subset of telco_churn) demographics/location etc. are to be dealt with.\n",
    "categorical_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom plot\n",
    "fig, axes = plt.subplots(9,2, figsize=(15,40))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(categorical_data)):\n",
    "    features = categorical_data[i]\n",
    "    sns.countplot(x=features, data=Telco_customer_churn_df, palette = 'Set2', ax=axes[i], hue='Churn Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_data = ['Monthly Charges', 'Churn Score', 'CLTV']\n",
    "fig, axes = plt.subplots(3,1, figsize=(10,15))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(continous_data)):\n",
    "    features = continous_data[i]\n",
    "    sns.histplot(x=features, data=Telco_customer_churn_df, ax=axes[i], palette='Paired', hue='Churn Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_data = ['Tenure in Months', 'Total Revenue', 'Total Charges']\n",
    "fig, axes = plt.subplots(3,1, figsize=(10,15))\n",
    "axes = axes.flatten()\n",
    "for i in range(len(continous_data)):\n",
    "    features = continous_data[i]\n",
    "    sns.histplot(x=features, data=Telco_customer_churn_services_df, ax=axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,10))\n",
    "sns.violinplot(Telco_customer_churn_demographics_df, y='Number of Dependents', color='m')\n",
    "plt.xlabel(\"Number of Dependents\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Number of Dependents Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of People around the city.\n",
    "fig = px.scatter_mapbox(\n",
    "    Telco_customer_churn_df,\n",
    "    lat = 'Latitude',\n",
    "    lon = 'Longitude',\n",
    "    color = 'Churn Score',\n",
    "    hover_name = 'Churn Value',\n",
    "    # size = 'Churn Value',\n",
    "    zoom = 5, \n",
    "    height = 800,\n",
    "    width = 800\n",
    ")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reason for churn -> most imp to analyze\n",
    "plt.figure(figsize=(25,40))\n",
    "sns.countplot(y='Churn Reason', data=Telco_customer_churn_df)\n",
    "# plt.legend()\n",
    "plt.title(\"Churn Reasons\")\n",
    "sns.set(font_scale=5)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Telco_customer_churn_df.copy()\n",
    "df.drop(['CustomerID', 'Lat Long', 'Churn Reason', 'Country', 'State', 'City', 'Zip Code', 'Churn Label', 'Count', 'Churn Score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cat_features = [\n",
    "    'Gender', 'Senior Citizen', 'Partner', 'Dependents', 'Phone Service', 'Multiple Lines',\n",
    "    'Internet Service','Online Security', 'Online Backup', 'Device Protection', 'Tech Support', \n",
    "    'Streaming TV', 'Streaming Movies', 'Contract','Paperless Billing', 'Payment Method'\n",
    "]\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_mat = ohe.fit_transform(df[dummy_cat_features])\n",
    "df_new = pd.DataFrame(encoded_mat, columns=ohe.get_feature_names_out(dummy_cat_features))\n",
    "df_new.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap{Matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"Churn Value\"].sort_values(ascending=False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(corr_matrix[\"Churn Value\"].sort_values(ascending=False).to_frame(), annot = True,linewidths = 0.4,linecolor = 'black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Churn Value'], axis=1).copy()\n",
    "Y = df['Churn Value']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Gaussian Naive Bayes' : GaussianNB(),\n",
    "    'K Nearest Neighbors' : KNeighborsClassifier(),\n",
    "    'Support Vector Machine' : SVC(probability=True),\n",
    "    'Decision Tree Classifier' : DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier' : RandomForestClassifier(),\n",
    "    'Bagging Classifier' : BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(),\n",
    "        n_estimators=10\n",
    "    ),\n",
    "    'Gradient Boosting Classifier' : GradientBoostingClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=50\n",
    "    ),\n",
    "    'Stacking Classifier' : StackingClassifier(\n",
    "        estimators=[\n",
    "            ('log_reg', LogisticRegression()),\n",
    "            ('random_forest', RandomForestClassifier()),\n",
    "            ('grad_boost', GradientBoostingClassifier())\n",
    "        ]\n",
    "    ),\n",
    "    'Voting Classifier' : VotingClassifier(\n",
    "        estimators=[\n",
    "            ('log_reg', LogisticRegression()),\n",
    "            ('random_forest', RandomForestClassifier()),\n",
    "            ('grad_boost', GradientBoostingClassifier())\n",
    "        ]\n",
    "    ),\n",
    "    'XgBoost' : XGBClassifier(),\n",
    "    'LightGBM' : LGBMClassifier(\n",
    "        scale_pos_weight =3,\n",
    "        random_state=42,\n",
    "        objective = 'binary'\n",
    "    ),\n",
    "    'Catboost' : CatBoostClassifier()\n",
    "    }\n",
    "model_accs = []\n",
    "model_precs = []\n",
    "model_recalls = []\n",
    "model_f1s = []\n",
    "\n",
    "\n",
    "# Models used for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'Logistic Regression' : {\n",
    "        'penalty' : ['l2', 'elasticnet'],\n",
    "        'C' : [0.1, 1, 10],\n",
    "        'max_iter' : [100, 1000, 10000]\n",
    "    },\n",
    "    'Gaussian Naive Bayes' : {}, # No hyperparameters to tune\n",
    "    'K Nearest Neighbors' : {\n",
    "        'n_neighbors' : [1, 5, 10],\n",
    "        'weights' : ['uniform', 'distance']\n",
    "    },\n",
    "    'Support Vector Machine' : {\n",
    "        'C' : [0.1, 1],\n",
    "        'kernel' : ['rbf'],\n",
    "        'gamma' : [0.1, 0.01]\n",
    "    },\n",
    "    'Decision Tree Classifier' : {\n",
    "        'criterion' : ['gini', 'log_loss'],\n",
    "        'max_depth' : [None, 10, 100]\n",
    "    },\n",
    "    'Random Forest Classifier' : {\n",
    "        'criterion' : ['gini', 'log_loss'],\n",
    "        'max_depth' : [None, 10, 100],\n",
    "        'n_estimators' : [100, 200, 300]\n",
    "    },\n",
    "    'Bagging Classifier' : {\n",
    "        'n_estimators' : [10, 20, 30, 100]\n",
    "    },\n",
    "    'Gradient Boosting Classifier' : {\n",
    "        'learning_rate' : [0.1, 1],\n",
    "        'n_estimators' : [100, 200, 300]\n",
    "    },\n",
    "    'AdaBoost' : {\n",
    "        'n_estimators' : [50, 100, 200, 300]\n",
    "    },\n",
    "    'Stacking Classifier' : {}, # No hyperparameter to tune\n",
    "    'Voting Classifier' : {}, # No hyperparameter to tune\n",
    "    'XgBoost' : {},\n",
    "    'LightGBM' : {\n",
    "        'learning_rate' : [0.1, 0.01],\n",
    "        'max_depth' : [-5, -10, -20] \n",
    "    },\n",
    "    'CatBoost' : {\n",
    "        'depth' : [6, 8, 10],\n",
    "        'learning_rate' : [0.01, 0.05, 0.1],\n",
    "        'iterations' : [30, 50, 100]\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    if model_name in param_grid:\n",
    "        hyper_parameters = param_grid[model_name]\n",
    "        grid_search = GridSearchCV(model, hyper_parameters, cv=5)\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        Y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        precision = precision_score(Y_test, Y_pred)\n",
    "        recall = recall_score(Y_test, Y_pred)\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "        # Appending the lists with scores\n",
    "        model_accs.append(accuracy_score)\n",
    "        model_precs.append(precision)\n",
    "        model_recalls.append(recall)\n",
    "        model_f1s.append(f1)\n",
    "\n",
    "        # confusion matrix could also be considered as done in the final project..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing performance metrics\n",
    "\n",
    "model_dict = {\n",
    "    'Model': models,\n",
    "    'Precision': model_precs,\n",
    "    'Acuuracy': model_accs,\n",
    "    'Recall': model_recalls,\n",
    "    'F1': model_f1s\n",
    "}\n",
    "\n",
    "models_df = pd.DataFrame(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputdeploy(input):\n",
    "    output = model_var.predict(input)\n",
    "\n",
    "\n",
    "\n",
    "gradio.Interface(outputdeploy, input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
